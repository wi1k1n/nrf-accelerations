\chapter{Introduction}
\label{chap:introduction}

% kind of problem statement in introduction
% positions required, but meshroom can be used
% scenes with highly specular objects trains better using log-transform
% discussion part: background color problem
% layer depth for NSVF can be way more shallow since voxel features
% assuming single(!) point(!) light only
% inverseCDF sampling for NSVF
% discrete regularization - noise to sigma field


% light attenuation + light as learnable parameter (as there barely exist the ground truth value for real datasets)
% different sigma in voxel strategies for inVoxelApproximation


The task of reconstructing a real 3D scene from a set of 2D captured images
and modeling it under novel viewing and light conditions
is a long-standing problem in computer graphics and vision.
Possible complex scene geometry along with numerous material qualities
make this task a tremendously challenging problem.

The applications of realistic rendering include diverse fields, such that
visualization, animation, virtual and augmented reality, visual effects,
and even computer vision and robot navigation.


Not very long about very basics
\subsection{\{Rendering equation\} \im{or/and radiometry?}}
\begin{enumerate}
    %\item Color space \im{?}
    \item LDR/HDR
    \item Rendering equation
    \item Transfer equation
    \item (simple) volume rendering
    \item BSSRDF + Reflection Models
\end{enumerate}
\sm{Not sure how relevant that is. Maybe put this in a subsection later for NeRF? Lowest priority for now.}

This task was traditionally addressed to the image-based rendering systems,
which use vision-based scene geometry together with image-based view interpolation. \cite{shumandkang2000}
However, recent works in this field make use of deep neural networks
in order to learn implicit "neural" scene representation,
containing both geometric and appearance information. \cite{tewari2020state}

\cite{mildenhall2020nerf} presented a state-of-the-art approach,
which uses deep neural network as an implicit scene representation
along with a ray-marching technique. 
This technique has quickly become a starting point for a lot of other works. \im{short list of main works here}
However, the main limitation for most of them is the lack of light interaction,
which disables the novel light conditions for the rendering scene.

% \section{Goal of the Thesis}
The goal of this thesis is to develop a solution
that is able to model scene geometry and appearance
with view- and light-dependant effects
implying colocated as well as non-colocated light sources.
This is done by utilizing sparse voxel octree approach,
proposed in \cite{liu2021neural} for increasing the performance.
\cite{bi2020neural} proposes the




% \section{Outline}
In Chapter 2 related background along with already existing methods are described.

Chapter 3 is dedicated to the proposed method.

Chapter 4 describes and analyses the experiments and the results.






% This is the Introduction and this is a text citation to \textcite{bestpaper} where this is a citation in parentheses \parencite{bestpaper}.

% \begin{figure}[!ht]
%     \centering
%     \begin{subfigure}[t]{0.485\textwidth}
%         \centering
%         \includegraphics[height = 0.2\textheight, keepaspectratio]{logo_white.jpg}
%         \caption{The CG logo}
%         \label{fig:logo_sub_1}
%     \end{subfigure}
%     \begin{subfigure}[t]{0.485\textwidth}
%         \centering
%         \includegraphics[height = 0.2\textheight, keepaspectratio]{logo_white.jpg}
%         \caption{The CG logo again}
%         \label{fig:logo_sub_2}
%     \end{subfigure}
%     \caption{The logo}
%     \label{fig:logo}
% \end{figure}

% So let us reference the logo above.

% cref : \cref{fig:logo} , \cref{fig:logo_sub_1} , \cref{fig:logo_sub_2}

% Cref : \Cref{fig:logo} , \Cref{fig:logo_sub_1} , \Cref{fig:logo_sub_2}


% \blankline
% Or reference the chapter.

% cref : \cref{chap:introduction}

% Cref : \Cref{chap:introduction}


% \lipsum[1]

% \begin{table*}[!htb]
%     \setArraystrech{1.5}
    
%     \centering
%     \caption{A fancy table showing some measured errors.}
%     \label{tab:benchmark}
%     \begin{tabular}{ L{0.2\textwidth}R{0.15\textwidth}R{0.15\textwidth}R{0.15\textwidth}R{0.15\textwidth}}
%     	\toprule
%     	Data sets                                    &   A &   B &   C &   D \\
%     	\addlinespace
%         \midrule
%         seq 1                                        & 0.1 & 0.2 & 0.3 & 0.4 \\
%     	seq 2                                        & 1.5 & 0.3 & 0.7 & 1.0 \\
%     	seq 3                                        & 0.4 & 0.7 & 9.4 & 0.9 \\ \bottomrule
%     \end{tabular}
% \end{table*}

% \lipsum[2]

